{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c22a870",
   "metadata": {},
   "source": [
    "Known protein modeler (ProtBERT, ESMfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726e33f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdjglkjdfhg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe124e7",
   "metadata": {},
   "source": [
    "Use known LLM to determine binding pockets etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094032d4",
   "metadata": {},
   "source": [
    "After parsing the input data should look like this, with a fasta protein ID, the protein sequence, and the 0/1 binary determining binding pocket residues\n",
    "\n",
    ">protein_id\n",
    "SEQUENCE\n",
    "000000000011111000000000000000000000000000000000000000000000000000000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7d4997c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.08 s\n",
      "Wall time: 5.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from Bio import SeqIO\n",
    "import gzip\n",
    "\n",
    "# Load protein sequences\n",
    "def load_fasta_sequences(fasta_path):\n",
    "    sequences = {}\n",
    "    with gzip.open(fasta_path, \"rt\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            raw_id = record.id.split()[0]  # remove any trailing description\n",
    "            if len(raw_id) >= 5:\n",
    "                pdb_id = raw_id[:4]\n",
    "                chain_id = raw_id[4:]\n",
    "                key = f\"{pdb_id}_{chain_id}\".lower()  # match BioLiP format\n",
    "                sequences[key] = str(record.seq)\n",
    "    return sequences\n",
    "\n",
    "# Parse BioLiP.txt\n",
    "def parse_biolip_annotations(biolip_path):\n",
    "    binding_map = {}  # protein_id -> set of binding residue indices\n",
    "    with gzip.open(biolip_path, \"rt\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) < 9:\n",
    "                continue\n",
    "            pdb_id = parts[0]\n",
    "            chain_id = parts[1]\n",
    "            binding_residues = parts[8]  # e.g., \"A:45,A:67,A:89\"\n",
    "            key = f\"{pdb_id}_{chain_id}\"\n",
    "            indices = set()\n",
    "            for res in binding_residues.split(\",\"):\n",
    "                if \":\" in res:\n",
    "                    _, idx = res.split(\":\")\n",
    "                    if idx.isdigit():\n",
    "                        indices.add(int(idx))\n",
    "            binding_map[key] = indices\n",
    "    return binding_map\n",
    "\n",
    "# Generate labeled output\n",
    "def generate_labeled_sequences(sequences, binding_map, output_path):\n",
    "    with open(output_path, \"w\") as out:\n",
    "        for protein_id, seq in sequences.items():\n",
    "            if protein_id not in binding_map:\n",
    "                continue\n",
    "            labels = [\"0\"] * len(seq)\n",
    "            for idx in binding_map[protein_id]:\n",
    "                if 0 <= idx < len(seq):\n",
    "                    labels[idx] = \"1\"\n",
    "            out.write(f\">{protein_id}\\n{seq}\\n{''.join(labels)}\\n\")\n",
    "\n",
    "# Paths to your files\n",
    "fasta_path = \"protein.fasta.gz\"\n",
    "biolip_path = \"BioLiP.txt.gz\"\n",
    "output_path = \"biolip_labeled.txt\"\n",
    "\n",
    "# Run preprocessing\n",
    "sequences = load_fasta_sequences(fasta_path)\n",
    "binding_map = parse_biolip_annotations(biolip_path)\n",
    "generate_labeled_sequences(sequences, binding_map, output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9f71bc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 32\n",
      "C: 34\n",
      "D: 35\n",
      "E: 36\n",
      "F: 37\n",
      "G: 38\n",
      "H: 39\n",
      "I: 40\n",
      "K: 42\n",
      "L: 43\n",
      "M: 44\n",
      "N: 45\n",
      "P: 47\n",
      "Q: 48\n",
      "R: 49\n",
      "S: 50\n",
      "T: 51\n",
      "V: 53\n",
      "W: 54\n",
      "Y: 56\n",
      "CPU times: total: 312 ms\n",
      "Wall time: 550 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Load pretrained tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "\n",
    "# Add amino acid tokens (if needed)\n",
    "amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "tokenizer.add_tokens(amino_acids)\n",
    "\n",
    "for aa in amino_acids:\n",
    "    print(f\"{aa}: {tokenizer.convert_tokens_to_ids(aa)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "40835b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 256)\n",
      "    (wpe): Embedding(1024, 256)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-5): 6 x GPT2Block(\n",
      "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D(nf=768, nx=256)\n",
      "          (c_proj): Conv1D(nf=256, nx=256)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=1024, nx=256)\n",
      "          (c_proj): Conv1D(nf=256, nx=1024)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=256, out_features=50257, bias=False)\n",
      ")\n",
      "Total parameters: 17,867,008\n",
      "CPU times: total: 5.62 s\n",
      "Wall time: 312 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Config\n",
    "\n",
    "config = GPT2Config(vocab_size=len(tokenizer), n_embd=256, n_layer=6, n_head=4)\n",
    "model = GPT2LMHeadModel(config)\n",
    "\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e44e951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch.nn as nn\n",
    "\n",
    "class PocketPredictor(nn.Module):\n",
    "    def __init__(self, gpt_model, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.gpt = gpt_model\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        hidden = self.gpt.transformer(input_ids).last_hidden_state  # Extract the tensor\n",
    "        return self.head(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0ec2ec8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 691])\n",
      "Decoded sequence: R R R R S V Q W C A V S Q P E A T K C F Q W Q R N M R K V R G P P V S C I K R D S P I Q C I Q A I A E N R A D A V T L D G G F I Y E A G L A P Y K L R P V A A E V Y G T E R Q P R T H Y Y A V A V V K K G G S F Q L N E L Q G L K S C H T G L R R T A G W N V P I G T L R P F L N W T G P P E P I E A A V A R F F S A S C V P G A D K G Q F P N L C R L C A G T G E N K C A F S S Q E P Y F S Y S G A F K C L R D G A G D V A F I R E S T V F E D L S D E A E R D E Y E L L C P D N T R K P V D K F K D C H L A R V P S H A V V A R S V N G K E D A I W N L L R Q A Q E K F G K D K S P K F Q L F G S P S G Q K D L L F K D S A I G F S R V P P R I D S G L Y L G S G Y F T A I Q N L R K S E E E V A A R R A R V V W C A V G E Q E L R K C N Q W S G L S E G S V T C S S A S T T E D C I A L V L K G E A D A M S L D E G Y V Y T A G K C G L V P V L A E N Y K S Q Q S S D P D P N C V D R P V E G Y L A V A V V R R S D T S L T W N S V K G K K S C H T A V D R T A G W N I P M G L L F N Q T G S C K F D E Y F S Q S C A P G S D P R S N L C A L C I G D E Q G E N K C V P N S N E R Y Y G Y T G A F R C L A E N A G D V A F V K D V T V L Q N T D G N N N E A W A K D L K L A D F A L L C L D G K R K P V T E A R S C H L A M A P N H A V V S R M D K V E R L K Q V L L H Q Q A K F G R N G S D C P D K F C L F Q S E T K N L L F N D N T E C L A R L H G K T T Y E K Y L G P Q Y V A G I T N L K K C S T S P L L E A C E F L R K\n",
      "Token IDs: [49, 49, 49, 49, 50, 53, 48, 54, 34, 32, 53, 50, 48, 47, 36, 32, 51, 42, 34, 37, 48, 54, 48, 49, 45, 44, 49, 42, 53, 49, 38, 47, 47, 53, 50, 34, 40, 42, 49, 35, 50, 47, 40, 48, 34, 40, 48, 32, 40, 32, 36, 45, 49, 32, 35, 32, 53, 51, 43, 35, 38, 38, 37, 40, 56, 36, 32, 38, 43, 32, 47, 56, 42, 43, 49, 47, 53, 32, 32, 36, 53, 56, 38, 51, 36, 49, 48, 47, 49, 51, 39, 56, 56, 32, 53, 32, 53, 53, 42, 42, 38, 38, 50, 37, 48, 43, 45, 36, 43, 48, 38, 43, 42, 50, 34, 39, 51, 38, 43, 49, 49, 51, 32, 38, 54, 45, 53, 47, 40, 38, 51, 43, 49, 47, 37, 43, 45, 54, 51, 38, 47, 47, 36, 47, 40, 36, 32, 32, 53, 32, 49, 37, 37, 50, 32, 50, 34, 53, 47, 38, 32, 35, 42, 38, 48, 37, 47, 45, 43, 34, 49, 43, 34, 32, 38, 51, 38, 36, 45, 42, 34, 32, 37, 50, 50, 48, 36, 47, 56, 37, 50, 56, 50, 38, 32, 37, 42, 34, 43, 49, 35, 38, 32, 38, 35, 53, 32, 37, 40, 49, 36, 50, 51, 53, 37, 36, 35, 43, 50, 35, 36, 32, 36, 49, 35, 36, 56, 36, 43, 43, 34, 47, 35, 45, 51, 49, 42, 47, 53, 35, 42, 37, 42, 35, 34, 39, 43, 32, 49, 53, 47, 50, 39, 32, 53, 53, 32, 49, 50, 53, 45, 38, 42, 36, 35, 32, 40, 54, 45, 43, 43, 49, 48, 32, 48, 36, 42, 37, 38, 42, 35, 42, 50, 47, 42, 37, 48, 43, 37, 38, 50, 47, 50, 38, 48, 42, 35, 43, 43, 37, 42, 35, 50, 32, 40, 38, 37, 50, 49, 53, 47, 47, 49, 40, 35, 50, 38, 43, 56, 43, 38, 50, 38, 56, 37, 51, 32, 40, 48, 45, 43, 49, 42, 50, 36, 36, 36, 53, 32, 32, 49, 49, 32, 49, 53, 53, 54, 34, 32, 53, 38, 36, 48, 36, 43, 49, 42, 34, 45, 48, 54, 50, 38, 43, 50, 36, 38, 50, 53, 51, 34, 50, 50, 32, 50, 51, 51, 36, 35, 34, 40, 32, 43, 53, 43, 42, 38, 36, 32, 35, 32, 44, 50, 43, 35, 36, 38, 56, 53, 56, 51, 32, 38, 42, 34, 38, 43, 53, 47, 53, 43, 32, 36, 45, 56, 42, 50, 48, 48, 50, 50, 35, 47, 35, 47, 45, 34, 53, 35, 49, 47, 53, 36, 38, 56, 43, 32, 53, 32, 53, 53, 49, 49, 50, 35, 51, 50, 43, 51, 54, 45, 50, 53, 42, 38, 42, 42, 50, 34, 39, 51, 32, 53, 35, 49, 51, 32, 38, 54, 45, 40, 47, 44, 38, 43, 43, 37, 45, 48, 51, 38, 50, 34, 42, 37, 35, 36, 56, 37, 50, 48, 50, 34, 32, 47, 38, 50, 35, 47, 49, 50, 45, 43, 34, 32, 43, 34, 40, 38, 35, 36, 48, 38, 36, 45, 42, 34, 53, 47, 45, 50, 45, 36, 49, 56, 56, 38, 56, 51, 38, 32, 37, 49, 34, 43, 32, 36, 45, 32, 38, 35, 53, 32, 37, 53, 42, 35, 53, 51, 53, 43, 48, 45, 51, 35, 38, 45, 45, 45, 36, 32, 54, 32, 42, 35, 43, 42, 43, 32, 35, 37, 32, 43, 43, 34, 43, 35, 38, 42, 49, 42, 47, 53, 51, 36, 32, 49, 50, 34, 39, 43, 32, 44, 32, 47, 45, 39, 32, 53, 53, 50, 49, 44, 35, 42, 53, 36, 49, 43, 42, 48, 53, 43, 43, 39, 48, 48, 32, 42, 37, 38, 49, 45, 38, 50, 35, 34, 47, 35, 42, 37, 34, 43, 37, 48, 50, 36, 51, 42, 45, 43, 43, 37, 45, 35, 45, 51, 36, 34, 43, 32, 49, 43, 39, 38, 42, 51, 51, 56, 36, 42, 56, 43, 38, 47, 48, 56, 53, 32, 38, 40, 51, 45, 43, 42, 42, 34, 50, 51, 50, 47, 43, 43, 36, 32, 34, 36, 37, 43, 49, 42]\n"
     ]
    }
   ],
   "source": [
    "sequence = \"RRRRSVQWCAVSQPEATKCFQWQRNMRKVRGPPVSCIKRDSPIQCIQAIAENRADAVTLDGGFIYEAGLAPYKLRPVAAEVYGTERQPRTHYYAVAVVKKGGSFQLNELQGLKSCHTGLRRTAGWNVPIGTLRPFLNWTGPPEPIEAAVARFFSASCVPGADKGQFPNLCRLCAGTGENKCAFSSQEPYFSYSGAFKCLRDGAGDVAFIRESTVFEDLSDEAERDEYELLCPDNTRKPVDKFKDCHLARVPSHAVVARSVNGKEDAIWNLLRQAQEKFGKDKSPKFQLFGSPSGQKDLLFKDSAIGFSRVPPRIDSGLYLGSGYFTAIQNLRKSEEEVAARRARVVWCAVGEQELRKCNQWSGLSEGSVTCSSASTTEDCIALVLKGEADAMSLDEGYVYTAGKCGLVPVLAENYKSQQSSDPDPNCVDRPVEGYLAVAVVRRSDTSLTWNSVKGKKSCHTAVDRTAGWNIPMGLLFNQTGSCKFDEYFSQSCAPGSDPRSNLCALCIGDEQGENKCVPNSNERYYGYTGAFRCLAENAGDVAFVKDVTVLQNTDGNNNEAWAKDLKLADFALLCLDGKRKPVTEARSCHLAMAPNHAVVSRMDKVERLKQVLLHQQAKFGRNGSDCPDKFCLFQSETKNLLFNDNTECLARLHGKTTYEKYLGPQYVAGITNLKKCSTSPLLEACEFLRK\"\n",
    "input_ids = tokenizer.encode(sequence, return_tensors=\"pt\")  # shape: [1, seq_len]\n",
    "\n",
    "print(\"Input shape:\", input_ids.shape)\n",
    "\n",
    "decoded = tokenizer.decode(input_ids[0])\n",
    "print(\"Decoded sequence:\", decoded)\n",
    "print(\"Token IDs:\", input_ids[0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9fa0fab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best match: 1cb6_a\n",
      "Score: 689.0\n"
     ]
    }
   ],
   "source": [
    "from Bio import pairwise2\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "query_seq = sequence\n",
    "best_match = None\n",
    "best_score = -1\n",
    "\n",
    "for pid, target_seq in sequences.items():\n",
    "    alignments = pairwise2.align.globalxx(query_seq, target_seq, one_alignment_only=True)\n",
    "    score = alignments[0].score\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_match = pid\n",
    "\n",
    "print(\"Best match:\", best_match)\n",
    "print(\"Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6d88a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import pairwise2\n",
    "from Bio.Seq import Seq\n",
    "import numpy as np\n",
    "\n",
    "def transfer_binding_labels(query_seq, template_seq, binding_indices):\n",
    "    # Run global alignment\n",
    "    alignment = pairwise2.align.globalxx(query_seq, template_seq, one_alignment_only=True)[0]\n",
    "    aligned_query = alignment.seqA\n",
    "    aligned_template = alignment.seqB\n",
    "\n",
    "    # Map binding labels from template to query\n",
    "    y_true = []\n",
    "    template_pos = -1  # position in template_seq\n",
    "    for q_char, t_char in zip(aligned_query, aligned_template):\n",
    "        if t_char != \"-\":\n",
    "            template_pos += 1\n",
    "        if q_char == \"-\":\n",
    "            continue  # skip gaps in query\n",
    "        if template_pos in binding_indices:\n",
    "            y_true.append(1)\n",
    "        else:\n",
    "            y_true.append(0)\n",
    "\n",
    "    return np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f8b7428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in binding_map: ['101m_A', '102m_A', '103m_A', '104m_A', '105m_A', '106m_A', '107m_A', '108m_A', '109m_A', '10gs_A']\n",
      "y_true shape: (691,)\n",
      "Aligned query:    RRR--------------------R---SVQ------WCA-------V-----S-QPEA----TKCF-Q---WQRNMR----------------------K-------V-----RGP----PVSCI---K--R--DSP--IQ----CIQA----------I--A--E----NRAD-A------V------T---------LDGG--FIY-EAGL-APY-K-L-----RP-----VAAE--VY--GTER-QPRTHYYAVAVVKKGG-S--------F--Q----L-N---------EL-QG-----L-KS-----C-------------------H------T----GL----R--R----------TA--------G----WNV--P-I----G--------T------------L-----RPF--L----N----WT---G---P---P------E---PIE-AA-VAR--F------------F--------SA---SC----------V-------PG-----------------A----------D-KGQFPNLCR----LCA--GT--G-EN---KC-A--F-S--SQ----EPYFS----YS-----------G---AF-------KC--LRD---GA-GDV-----AFIR--------E---------ST---VFED------L---SDEA--ERD--EY--EL--LC------PD-----N-T-------R---------------KP--------VD-----KF------KDCH-LAR-----VP---------SHA--VV----ARS----V-NGK-ED----AIWN------L-LR--------Q-AQE------K---F-GKD-------K--S----------PK------------------F---------QL---FGS-----------P----SG----QKDL----L----FK------D-SAIG---------F-----------S----R---VP----------------P-----RI---D-------S-----G-----LYLG----------SGYF--TAI--Q-----------------------N-L--RK--SEEE--------VAA----------R--RA--------R------V---V------------------W-C-A--------------V-GEQ-------E-L----RK---C---NQWSGL-SEG----SVT-C--------SS-----A---ST-T-EDC---IAL--------V-L-KGE-A----DA------------M---S----LDE-GYVY---TA----G-KC--GLVPV--L-------------AENYKSQQSS-----------DP---DP----NCV-DRPVEGY-L--AV----AV-----V-R-------------------R--------S--D-T----S--L-TW-N----S--VKGKKS-CHTAV------D---R--T-A-----------GWN-IPM-G---L--LFNQT--G----SCKFDEYFS-Q-----SC-A----P-----GS------DPR--SN-----LCA-LCI---G---DEQG-EN----KCV-PN-S----NERYY--G-----YTGAFR---C-LA-ENA-GDVAFVK------------DV------------TV-L-QNTD--------GNNNEAWAKDLK--LADF---A-L--LCLD------GKRK---------PV--T--------E---------------------A----RSC--H---------LA--------M-APNHAV-----V-SR-------------M----------------DK---V--E------------R-----L--K-----QV--L-------------L----------HQ-----QA-----KF--GR--------N-----GS------D-----------------C-PD--------KFC-L--FQS-ET------K---------------------N----L--------------L--------------F--------N---------------D----N-----T---------E--------CLA--------RLH-------G--KT----TYE------KY-------LG-P-------------QYVAG-------I-------T--N-LKKC-S-----T----------SP------L-L-----EACEFL---RK-\n",
      "Aligned template: ---NHADYNLNSPLISDDIDNLIRKFNS--LPIPSMW--DSKNWDGVLEMLTSCQ--ANPIST---SQMHKW---M-GSWLMSDNHDASQGYSFLHEVDKEAEITFDVVETFIRG-WGNKP---IEYIKKERWTDS-FKI-LAYLC-Q-KFLDLHKLTLILNAVSEVELLN---LARTFKGKVRRSSHGTNICRIRVPSL--GPTFI-SE-G-WA-YFKKLDILMDR-NFLLMV---KDV-IIG--RMQ--T-------V----LSMVCRIDNLFSEQDIFSLLNIYRIGDKIVE-RQGNFSYDLIK-MVEPICNLKLMKLARESRPLVPQFPHFENHIKTSVDEG-AKIDRGIRFLHDQIMSVKT-VDLTLVIYGSFRHW--GHPFIDYYTGLEKLHSQVTMKKDIDVSYAKALASDLAR--IVLFQQFNDHKKW-FVNGDLLPHDHPFKSHVKENTWP--TAAQV--QDFGDKWHELPLIKCFEIPDLLDPS-IIYS-DKSHSMNRSEVLKHVRMNP-NTPIPSKKVLQTMLDTKATNWKEFLKEIDEKG----L--DDDDL--IIG-LKGKE-RELK-LAGRFFSLMS-WKLRE-YF-VITEY-LIKTHFVPMFKGLTMA-DDLTAVIK-KML-DSSSG-QG--LKSYEA-I-CIANHIDYEKWNNHQRKLS-NGPVF--RVMGQFLGYPS---LIER-THE-FFE-KSL-IYYNGRPDLMRVHNNTLINSTSQRVCWQGQEGGLEGLRQK-GWTILNLLV-IQREAK-IRNTAVK---VLA-QGDNQV-ICTQYKTKKS--RNVVELQGA--LNQMVSN--NE-KIMTAI--KIGTGKLGL-LINDDETMQSA--DYLNYGKIPIFRG--VIRGLETKRWSRVTCVTNDQIP-TCANIMSSVSTNALTVAHFAENPINAMIQ-YNYFG-TFARLLLMMHDPALRQS-LYEVQ-D-KIPGLHSSTFKYAMLYLDPS-IGGVSGMSLSRFLIRAFPDPVTESLSFWRFIHV-HARSEHLKEMSAVFGNPEIAKFRITHIDKLVEDPTSLNIAMGMSPANL-L-KTEVKKCLIES---RQT-IRNQVIKDATIYLYHEEDRLRSFLWSINPLFPR-FLS--EFKSGTFLGV-ADGLISLFQNSRTIR-NSFKKKYHRELDDLIVRSEVSSLTHLGKLHLRRGSCKMWTCSATHADTLRYKSWGRTVIG--TTVPHPLEMLGPQHRKETPCAPCN-----TS-GFNYVSV-HCPDGIHDVFSSRGPLPAYLGS-KTSE--STSI-LQPWERESKVPLIK--RATRLRDAISWFVEPDSKLAMTILSNIHSL--TG---EEWT-KRQHGFK-RTG----SALHRFSTSRMSHGGFA----S-Q-STAALTRLMATTD-TMRD-LGDQN--FD------FLFQA-TLLYA-QITTTVARDGWITSCTDHYHIACKSCLRPIEEITLDSSMDYTPPDVSHVLKTWRNGEGQSYQV-G---RC----IGFLYGDLAYRKSTHAEDSSLFPLSIQG--RI--RGRGFLKGL----LDGLMRASC-------CQVIHRRS-LAHLKRPANAVYG-GLIYLID--KLS-VSPPFL--SL--TRSGPIRDE--LE-TIPHK--IP-TSYPTSN-R--DMGVIVRNY---F-KYQCRL-IE--KG-----KYRSHYSQLWLFSDVLSIDFIGPFSIST-TLLQ---ILYKPFLSG-------KD-KNEL---RELANLSSL-L-RSYPPWG-R-ESRGTITTIPVYYTTTPYPKMLEMPPRIQNPLLSGIRLGQLPTGAHYKIRS-ILHGMGIHYRDFL-SCGDGSGGMTA---A-LLRENVHSRGIFNSLLELSGSVMRGASPEPPSALETLGGDKSRCVNGETCWEYPSDLCDPRTWDYFLRLKAGLGLQ-IDLIVMDMEVRDSSTSLKIETNVRNYVH-RILDEQ-GVLIYK-TYG-TYICESEKNAVTILG-PMFKTVDLVQTEFSSSQTSEVYMVCKPDWSSINESWK--NLYAFQSSE-QEFARAKKVSTYFTLTGIPSQFIPDPFVNIETMLQIFGVPTGVSHAAALKSSDRPADLLTISLFYMAIISYYNINHIRVGPIPPNPPSDGIAQNVGIAITGISFWLSLMEKDIPLYQQCLAVIQQSFPIR--WEAVSVKGGYK-QKWST--RGDGLPK-DTRISDSL-APIGNWIRSLELVRNQ-V--RLNPFNEILFNQLCRTVDNHL-K-WSNLRRNTGMIEWINRRIS-KEDRSILMLKSDLHE--E--NSWR-D\n",
      "Alignment score:  399.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys in binding_map:\", list(binding_map.keys())[:10])\n",
    "query_seq = Seq(sequence)\n",
    "template_seq = Seq(sequences[\"5a22_a\"])\n",
    "binding_indices = binding_map[\"5a22_A\"]\n",
    "\n",
    "y_true = transfer_binding_labels(query_seq, template_seq, binding_indices)\n",
    "print(\"y_true shape:\", y_true.shape)  # should be (83,)\n",
    "alignment = pairwise2.align.globalxx(query_seq, template_seq, one_alignment_only=True)[0]\n",
    "\n",
    "print(\"Aligned query:   \", alignment.seqA)\n",
    "print(\"Aligned template:\", alignment.seqB)\n",
    "print(\"Alignment score: \", alignment.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a1e69291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (691,)\n",
      "Sample predictions: [0.43492684 0.43918118 0.4395398  0.49329808 0.50368553 0.49490663\n",
      " 0.5472627  0.47116613 0.5474742  0.49970692]\n",
      "Predicted pocket residue indices: [  4   6   8  17  25  28  29  32  33  36  37  39  41  42  43  44  45  46\n",
      "  47  48  49  52  53  54  55  56  57  58  59  60  62  63  64  65  66  67\n",
      "  68  69  72  73  74  75  76  77  78  79  80  83  84  86  87  89  90  91\n",
      "  92  94  95  96  98  99 100 102 103 104 105 106 109 110 111 112 114 116\n",
      " 117 118 119 121 122 123 124 126 127 128 131 132 133 134 135 136 138 139\n",
      " 140 141 142 143 144 145 146 147 148 150 151 152 154 156 159 160 161 162\n",
      " 163 164 165 166 167 168 169 170 171 172 174 176 178 179 180 181 182 185\n",
      " 187 189 190 194 195 196 197 198 201 202 203 204 205 206 207 208 212 213\n",
      " 214 215 217 219 220 221 222 223 224 225 227 228 229 230 232 233 235 236\n",
      " 237 238 239 240 241 242 243 244 246 247 249 250 252 253 254 255 256 258\n",
      " 259 260 261 263 264 265 266 267 268 269 270 271 272 273 275 276 277 278\n",
      " 279 280 281 284 285 287 288 289 291 292 293 295 297 298 299 300 301 302\n",
      " 303 304 306 308 309 310 311 312 313 315 317 318 319 320 321 322 324 325\n",
      " 326 327 328 329 330 331 332 333 335 336 337 338 339 341 342 343 344 346\n",
      " 347 348 351 352 353 354 356 357 358 359 360 362 363 365 366 368 370 371\n",
      " 372 373 375 377 378 379 380 382 383 384 385 386 387 388 390 391 393 394\n",
      " 395 397 398 400 401 403 404 405 406 408 409 410 411 412 413 415 417 418\n",
      " 421 423 424 425 426 428 429 430 432 433 435 436 437 438 439 440 441 442\n",
      " 444 445 447 449 452 453 454 455 456 458 460 461 462 463 464 465 466 469\n",
      " 470 471 472 473 475 476 478 479 480 482 483 484 485 486 487 488 490 491\n",
      " 492 493 494 495 497 498 500 501 502 503 504 505 506 507 509 510 511 512\n",
      " 513 514 515 516 517 518 519 521 522 523 528 529 530 531 532 533 535 536\n",
      " 538 540 541 543 544 545 546 547 549 551 552 554 555 556 557 558 559 560\n",
      " 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 579 580\n",
      " 581 582 583 584 585 586 588 589 590 591 592 593 594 595 596 597 598 601\n",
      " 603 604 605 606 608 609 610 611 612 613 614 615 617 619 621 624 625 626\n",
      " 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 644 645\n",
      " 646 647 648 649 650 652 653 654 655 658 659 660 662 663 664 665 666 668\n",
      " 669 671 672 673 674 675 676 677 680 681 682 683 684 686 688 689 690]\n",
      "CPU times: total: 4.45 s\n",
      "Wall time: 189 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "pocket_model = PocketPredictor(model, hidden_dim=256)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = pocket_model(input_ids)  # shape: [1, 83, 1]\n",
    "    y_pred_probs = output.squeeze(0).squeeze(-1).numpy()  # shape: [83]\n",
    "\n",
    "print(\"Shape:\", y_pred_probs.shape)\n",
    "print(\"Sample predictions:\", y_pred_probs[:10])\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "print(\"Predicted pocket residue indices:\", np.where(y_pred == 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c11d4036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true shape: (691,)\n",
      "y_pred_probs shape: (691,)\n",
      "y_pred shape: (691,)\n",
      "Positive labels in y_true: 0\n",
      "Predicted positives: 521\n",
      "ROC AUC: nan\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F1 Score: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xincr\\OneDrive\\Desktop\\protLLM-2\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\xincr\\OneDrive\\Desktop\\protLLM-2\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# y_true: binary labels (0/1), y_pred_probs: predicted probabilities\n",
    "query_seq = Seq(sequence)  # your actual 83-residue input\n",
    "template_seq = Seq(sequences[\"5a22_a\"])\n",
    "binding_indices = binding_map[\"5a22_A\"]\n",
    "\n",
    "def transfer_binding_labels_full(query_seq, template_seq, binding_indices):\n",
    "    alignment = pairwise2.align.globalxx(query_seq, template_seq, one_alignment_only=True)[0]\n",
    "    aligned_query = alignment.seqA\n",
    "    aligned_template = alignment.seqB\n",
    "\n",
    "    y_true = []\n",
    "    template_pos = -1\n",
    "    query_pos = -1\n",
    "\n",
    "    for q_char, t_char in zip(aligned_query, aligned_template):\n",
    "        if t_char != \"-\":\n",
    "            template_pos += 1\n",
    "        if q_char != \"-\":\n",
    "            query_pos += 1\n",
    "            if template_pos in binding_indices:\n",
    "                y_true.append(1)\n",
    "            else:\n",
    "                y_true.append(0)\n",
    "\n",
    "    # Pad or truncate to match query length\n",
    "    if len(y_true) < len(query_seq):\n",
    "        y_true += [0] * (len(query_seq) - len(y_true))\n",
    "    elif len(y_true) > len(query_seq):\n",
    "        y_true = y_true[:len(query_seq)]\n",
    "\n",
    "    return np.array(y_true)\n",
    "\n",
    "y_true = transfer_binding_labels_full(query_seq, template_seq, binding_indices)\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred_probs > threshold).astype(int)\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_pred_probs)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(\"y_true shape:\", y_true.shape)\n",
    "print(\"y_pred_probs shape:\", y_pred_probs.shape)\n",
    "print(\"y_pred shape:\", y_pred.shape)\n",
    "print(\"Positive labels in y_true:\", np.sum(y_true))\n",
    "print(\"Predicted positives:\", np.sum(y_pred))\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5edeea22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m true_pocket = \u001b[38;5;28mset\u001b[39m(i \u001b[38;5;28;01mfor\u001b[39;00m i, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(y_true) \u001b[38;5;28;01mif\u001b[39;00m label == \u001b[32m1\u001b[39m)\n\u001b[32m      2\u001b[39m predicted_pocket = \u001b[38;5;28mset\u001b[39m(i \u001b[38;5;28;01mfor\u001b[39;00m i, prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(y_pred_probs) \u001b[38;5;28;01mif\u001b[39;00m prob > threshold)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m coverage = \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrue_pocket\u001b[49m\u001b[43m \u001b[49m\u001b[43m&\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_pocket\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrue_pocket\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m overlap = \u001b[38;5;28mlen\u001b[39m(true_pocket & predicted_pocket) / \u001b[38;5;28mlen\u001b[39m(predicted_pocket)\n",
      "\u001b[31mZeroDivisionError\u001b[39m: division by zero"
     ]
    }
   ],
   "source": [
    "true_pocket = set(i for i, label in enumerate(y_true) if label == 1)\n",
    "predicted_pocket = set(i for i, prob in enumerate(y_pred_probs) if prob > threshold)\n",
    "\n",
    "coverage = len(true_pocket & predicted_pocket) / len(true_pocket)\n",
    "overlap = len(true_pocket & predicted_pocket) / len(predicted_pocket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe90eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch 1XYZ, async=0\n",
    "select predicted_pocket, resi 45+67+89  # replace with predicted residue indices\n",
    "color red, predicted_pocket\n",
    "show surface, predicted_pocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5af3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_pocket_predictions(y_true, y_pred_probs, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate binding pocket predictions.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.array): Binary ground truth labels (0 = non-pocket, 1 = pocket)\n",
    "        y_pred_probs (np.array): Predicted probabilities for each residue\n",
    "        threshold (float): Classification threshold for binary decision\n",
    "\n",
    "    Returns:\n",
    "        dict: Evaluation metrics\n",
    "    \"\"\"\n",
    "    y_pred = (y_pred_probs > threshold).astype(int)\n",
    "\n",
    "    # Residue-level metrics\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_probs)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    # Pocket-level coverage\n",
    "    true_pocket = set(np.where(y_true == 1)[0])\n",
    "    predicted_pocket = set(np.where(y_pred == 1)[0])\n",
    "    coverage = len(true_pocket & predicted_pocket) / len(true_pocket) if true_pocket else 0.0\n",
    "    overlap = len(true_pocket & predicted_pocket) / len(predicted_pocket) if predicted_pocket else 0.0\n",
    "\n",
    "    return {\n",
    "        \"ROC-AUC\": roc_auc,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1\": f1,\n",
    "        \"Pocket Coverage\": coverage,\n",
    "        \"Pocket Overlap\": overlap\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67632f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated predictions\n",
    "y_true = np.array([0, 0, 1, 1, 0, 0, 1, 0, 0])\n",
    "y_pred_probs = np.array([0.1, 0.2, 0.8, 0.7, 0.3, 0.2, 0.9, 0.1, 0.05])\n",
    "\n",
    "metrics = evaluate_pocket_predictions(y_true, y_pred_probs)\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56d9e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nglview as nv\n",
    "view = nv.show_file(\"1XYZ.pdb\")\n",
    "view.add_representation(\"spacefill\", selection=\"45 or 67 or 89\", color=\"red\")\n",
    "view"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
